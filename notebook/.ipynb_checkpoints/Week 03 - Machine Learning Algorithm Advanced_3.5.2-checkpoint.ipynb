{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 머신러닝 알고리즘 적용 _ 심화\n",
    "    - 데이터 : 사용자 데이터 + 상품 데이터(과거 상품 구매 이력)\n",
    "    - 신규 모델 : RandomForest, ExtraTrees, BaggingClassifier, (XGBoost)\n",
    "    - 업데이트된 데이터 + 기존 모델(DT, LR) 평가척도 \n",
    "    - 업데이트된 데이터 + 신규 모델 평가척도\n",
    "    - [+2] 피쳐 엔지니어링\n",
    "    - [+2] 매개변수 조정\n",
    "    - 캐글 제출 \n",
    "    - 머신러닝 파이프라인 흐름도 기록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import operator\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import log_loss, f1_score, accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45619, 246) (45619, 1) (929615, 246)\n"
     ]
    }
   ],
   "source": [
    "# 신규 데이터 로딩\n",
    "\n",
    "trn = pd.read_csv('../input/train_append_lb_lag.csv').fillna(0)\n",
    "target = pd.DataFrame(pickle.load(open('../input/target.pkl','rb')), columns=['target'])\n",
    "tst = pd.read_csv('../input/test_append_lb_lag.csv').fillna(0)\n",
    "print(trn.shape, target.shape, tst.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "antiguedad\n",
      "canal_entrada\n",
      "cod_prov\n",
      "conyuemp\n",
      "fecha_alta\n",
      "ind_actividad_cliente\n",
      "ind_empleado\n",
      "ind_nuevo\n",
      "indext\n",
      "indfall\n",
      "indrel\n",
      "indrel_1mes\n",
      "indresi\n",
      "nomprov\n",
      "pais_residencia\n",
      "renta\n",
      "segmento\n",
      "sexo\n",
      "tiprel_1mes\n",
      "ult_fec_cli_1t\n",
      "age_lag_one\n",
      "antiguedad_lag_one\n",
      "canal_entrada_lag_one\n",
      "cod_prov_lag_one\n",
      "conyuemp_lag_one\n",
      "fecha_alta_lag_one\n",
      "ind_actividad_cliente_lag_one\n",
      "ind_ahor_fin_ult1_lag_one\n",
      "ind_aval_fin_ult1_lag_one\n",
      "ind_cco_fin_ult1_lag_one\n",
      "ind_cder_fin_ult1_lag_one\n",
      "ind_cno_fin_ult1_lag_one\n",
      "ind_ctju_fin_ult1_lag_one\n",
      "ind_ctma_fin_ult1_lag_one\n",
      "ind_ctop_fin_ult1_lag_one\n",
      "ind_ctpp_fin_ult1_lag_one\n",
      "ind_deco_fin_ult1_lag_one\n",
      "ind_dela_fin_ult1_lag_one\n",
      "ind_deme_fin_ult1_lag_one\n",
      "ind_ecue_fin_ult1_lag_one\n",
      "ind_empleado_lag_one\n",
      "ind_fond_fin_ult1_lag_one\n",
      "ind_hip_fin_ult1_lag_one\n",
      "ind_nom_pens_ult1_lag_one\n",
      "ind_nomina_ult1_lag_one\n",
      "ind_nuevo_lag_one\n",
      "ind_plan_fin_ult1_lag_one\n",
      "ind_pres_fin_ult1_lag_one\n",
      "ind_reca_fin_ult1_lag_one\n",
      "ind_recibo_ult1_lag_one\n",
      "ind_tjcr_fin_ult1_lag_one\n",
      "ind_valo_fin_ult1_lag_one\n",
      "ind_viv_fin_ult1_lag_one\n",
      "indext_lag_one\n",
      "indfall_lag_one\n",
      "indrel_lag_one\n",
      "indrel_1mes_lag_one\n",
      "indresi_lag_one\n",
      "nomprov_lag_one\n",
      "pais_residencia_lag_one\n",
      "renta_lag_one\n",
      "segmento_lag_one\n",
      "sexo_lag_one\n",
      "tiprel_1mes_lag_one\n",
      "ult_fec_cli_1t_lag_one\n",
      "age_lag_two\n",
      "antiguedad_lag_two\n",
      "canal_entrada_lag_two\n",
      "cod_prov_lag_two\n",
      "conyuemp_lag_two\n",
      "fecha_alta_lag_two\n",
      "ind_actividad_cliente_lag_two\n",
      "ind_ahor_fin_ult1_lag_two\n",
      "ind_aval_fin_ult1_lag_two\n",
      "ind_cco_fin_ult1_lag_two\n",
      "ind_cder_fin_ult1_lag_two\n",
      "ind_cno_fin_ult1_lag_two\n",
      "ind_ctju_fin_ult1_lag_two\n",
      "ind_ctma_fin_ult1_lag_two\n",
      "ind_ctop_fin_ult1_lag_two\n",
      "ind_ctpp_fin_ult1_lag_two\n",
      "ind_deco_fin_ult1_lag_two\n",
      "ind_dela_fin_ult1_lag_two\n",
      "ind_deme_fin_ult1_lag_two\n",
      "ind_ecue_fin_ult1_lag_two\n",
      "ind_empleado_lag_two\n",
      "ind_fond_fin_ult1_lag_two\n",
      "ind_hip_fin_ult1_lag_two\n",
      "ind_nom_pens_ult1_lag_two\n",
      "ind_nomina_ult1_lag_two\n",
      "ind_nuevo_lag_two\n",
      "ind_plan_fin_ult1_lag_two\n",
      "ind_pres_fin_ult1_lag_two\n",
      "ind_reca_fin_ult1_lag_two\n",
      "ind_recibo_ult1_lag_two\n",
      "ind_tjcr_fin_ult1_lag_two\n",
      "ind_valo_fin_ult1_lag_two\n",
      "ind_viv_fin_ult1_lag_two\n",
      "indext_lag_two\n",
      "indfall_lag_two\n",
      "indrel_lag_two\n",
      "indrel_1mes_lag_two\n",
      "indresi_lag_two\n",
      "nomprov_lag_two\n",
      "pais_residencia_lag_two\n",
      "renta_lag_two\n",
      "segmento_lag_two\n",
      "sexo_lag_two\n",
      "tiprel_1mes_lag_two\n",
      "ult_fec_cli_1t_lag_two\n",
      "age_lag_thr\n",
      "antiguedad_lag_thr\n",
      "canal_entrada_lag_thr\n",
      "cod_prov_lag_thr\n",
      "conyuemp_lag_thr\n",
      "fecha_alta_lag_thr\n",
      "ind_actividad_cliente_lag_thr\n",
      "ind_ahor_fin_ult1_lag_thr\n",
      "ind_aval_fin_ult1_lag_thr\n",
      "ind_cco_fin_ult1_lag_thr\n",
      "ind_cder_fin_ult1_lag_thr\n",
      "ind_cno_fin_ult1_lag_thr\n",
      "ind_ctju_fin_ult1_lag_thr\n",
      "ind_ctma_fin_ult1_lag_thr\n",
      "ind_ctop_fin_ult1_lag_thr\n",
      "ind_ctpp_fin_ult1_lag_thr\n",
      "ind_deco_fin_ult1_lag_thr\n",
      "ind_dela_fin_ult1_lag_thr\n",
      "ind_deme_fin_ult1_lag_thr\n",
      "ind_ecue_fin_ult1_lag_thr\n",
      "ind_empleado_lag_thr\n",
      "ind_fond_fin_ult1_lag_thr\n",
      "ind_hip_fin_ult1_lag_thr\n",
      "ind_nom_pens_ult1_lag_thr\n",
      "ind_nomina_ult1_lag_thr\n",
      "ind_nuevo_lag_thr\n",
      "ind_plan_fin_ult1_lag_thr\n",
      "ind_pres_fin_ult1_lag_thr\n",
      "ind_reca_fin_ult1_lag_thr\n",
      "ind_recibo_ult1_lag_thr\n",
      "ind_tjcr_fin_ult1_lag_thr\n",
      "ind_valo_fin_ult1_lag_thr\n",
      "ind_viv_fin_ult1_lag_thr\n",
      "indext_lag_thr\n",
      "indfall_lag_thr\n",
      "indrel_lag_thr\n",
      "indrel_1mes_lag_thr\n",
      "indresi_lag_thr\n",
      "nomprov_lag_thr\n",
      "pais_residencia_lag_thr\n",
      "renta_lag_thr\n",
      "segmento_lag_thr\n",
      "sexo_lag_thr\n",
      "tiprel_1mes_lag_thr\n",
      "ult_fec_cli_1t_lag_thr\n",
      "age_lag_fou\n",
      "antiguedad_lag_fou\n",
      "canal_entrada_lag_fou\n",
      "cod_prov_lag_fou\n",
      "conyuemp_lag_fou\n",
      "fecha_alta_lag_fou\n",
      "ind_actividad_cliente_lag_fou\n",
      "ind_ahor_fin_ult1_lag_fou\n",
      "ind_aval_fin_ult1_lag_fou\n",
      "ind_cco_fin_ult1_lag_fou\n",
      "ind_cder_fin_ult1_lag_fou\n",
      "ind_cno_fin_ult1_lag_fou\n",
      "ind_ctju_fin_ult1_lag_fou\n",
      "ind_ctma_fin_ult1_lag_fou\n",
      "ind_ctop_fin_ult1_lag_fou\n",
      "ind_ctpp_fin_ult1_lag_fou\n",
      "ind_deco_fin_ult1_lag_fou\n",
      "ind_dela_fin_ult1_lag_fou\n",
      "ind_deme_fin_ult1_lag_fou\n",
      "ind_ecue_fin_ult1_lag_fou\n",
      "ind_empleado_lag_fou\n",
      "ind_fond_fin_ult1_lag_fou\n",
      "ind_hip_fin_ult1_lag_fou\n",
      "ind_nom_pens_ult1_lag_fou\n",
      "ind_nomina_ult1_lag_fou\n",
      "ind_nuevo_lag_fou\n",
      "ind_plan_fin_ult1_lag_fou\n",
      "ind_pres_fin_ult1_lag_fou\n",
      "ind_reca_fin_ult1_lag_fou\n",
      "ind_recibo_ult1_lag_fou\n",
      "ind_tjcr_fin_ult1_lag_fou\n",
      "ind_valo_fin_ult1_lag_fou\n",
      "ind_viv_fin_ult1_lag_fou\n",
      "indext_lag_fou\n",
      "indfall_lag_fou\n",
      "indrel_lag_fou\n",
      "indrel_1mes_lag_fou\n",
      "indresi_lag_fou\n",
      "nomprov_lag_fou\n",
      "pais_residencia_lag_fou\n",
      "renta_lag_fou\n",
      "segmento_lag_fou\n",
      "sexo_lag_fou\n",
      "tiprel_1mes_lag_fou\n",
      "ult_fec_cli_1t_lag_fou\n",
      "age_lag_fiv\n",
      "antiguedad_lag_fiv\n",
      "canal_entrada_lag_fiv\n",
      "cod_prov_lag_fiv\n",
      "conyuemp_lag_fiv\n",
      "fecha_alta_lag_fiv\n",
      "ind_actividad_cliente_lag_fiv\n",
      "ind_ahor_fin_ult1_lag_fiv\n",
      "ind_aval_fin_ult1_lag_fiv\n",
      "ind_cco_fin_ult1_lag_fiv\n",
      "ind_cder_fin_ult1_lag_fiv\n",
      "ind_cno_fin_ult1_lag_fiv\n",
      "ind_ctju_fin_ult1_lag_fiv\n",
      "ind_ctma_fin_ult1_lag_fiv\n",
      "ind_ctop_fin_ult1_lag_fiv\n",
      "ind_ctpp_fin_ult1_lag_fiv\n",
      "ind_deco_fin_ult1_lag_fiv\n",
      "ind_dela_fin_ult1_lag_fiv\n",
      "ind_deme_fin_ult1_lag_fiv\n",
      "ind_ecue_fin_ult1_lag_fiv\n",
      "ind_empleado_lag_fiv\n",
      "ind_fond_fin_ult1_lag_fiv\n",
      "ind_hip_fin_ult1_lag_fiv\n",
      "ind_nom_pens_ult1_lag_fiv\n",
      "ind_nomina_ult1_lag_fiv\n",
      "ind_nuevo_lag_fiv\n",
      "ind_plan_fin_ult1_lag_fiv\n",
      "ind_pres_fin_ult1_lag_fiv\n",
      "ind_reca_fin_ult1_lag_fiv\n",
      "ind_recibo_ult1_lag_fiv\n",
      "ind_tjcr_fin_ult1_lag_fiv\n",
      "ind_valo_fin_ult1_lag_fiv\n",
      "ind_viv_fin_ult1_lag_fiv\n",
      "indext_lag_fiv\n",
      "indfall_lag_fiv\n",
      "indrel_lag_fiv\n",
      "indrel_1mes_lag_fiv\n",
      "indresi_lag_fiv\n",
      "nomprov_lag_fiv\n",
      "pais_residencia_lag_fiv\n",
      "renta_lag_fiv\n",
      "segmento_lag_fiv\n",
      "sexo_lag_fiv\n",
      "tiprel_1mes_lag_fiv\n",
      "ult_fec_cli_1t_lag_fiv\n"
     ]
    }
   ],
   "source": [
    "# 신규 데이터 설명\n",
    "for col in trn.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True], dtype=bool)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련 데이터와 테스트 데이터 동일 여부 확인\n",
    "trn.columns == tst.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moonhwi\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:129: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 9452\n",
      "1 1934\n",
      "2 55\n",
      "3 349\n",
      "4 222\n",
      "5 154\n",
      "6 503\n",
      "7 33\n",
      "8 1085\n",
      "9 1219\n",
      "10 246\n",
      "11 21\n",
      "12 2942\n",
      "13 4733\n",
      "14 159\n",
      "15 5151\n",
      "16 8218\n",
      "17 9119\n"
     ]
    }
   ],
   "source": [
    "# 빈도가 낮은 타겟은 사전에 제거 (이유: 교차 검증에 활용할 수 없음 + 너무 빈도가 낮아 무의미함)\n",
    "rem_targets = [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 21, 22, 23]  # 18 classes\n",
    "trn = trn[target['target'].isin(rem_targets)]\n",
    "target = target[target['target'].isin(rem_targets)]\n",
    "target = LabelEncoder().fit_transform(target)\n",
    "\n",
    "for t in np.unique(target):\n",
    "    print(t, sum(target==t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 평가용 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(x, y, model):\n",
    "    trn_scores = dict(); vld_scores = dict()\n",
    "    sss = StratifiedShuffleSplit(n_splits=3, test_size=0.1, random_state=777)\n",
    "    for t_ind, v_ind in sss.split(x,y):\n",
    "        # split data\n",
    "        x_trn, x_vld = x.iloc[t_ind], x.iloc[v_ind]\n",
    "        y_trn, y_vld = y[t_ind], y[v_ind]\n",
    "\n",
    "        # fit model\n",
    "        model.fit(x_trn, y_trn)\n",
    "        \n",
    "        # eval _ trn        \n",
    "        preds = model.predict_proba(x_trn)\n",
    "\n",
    "        log_scores = trn_scores.get('log loss', [])\n",
    "        log_scores.append(log_loss(y_trn, preds))\n",
    "        trn_scores['log loss'] = log_scores\n",
    "\n",
    "        # eval _ vld\n",
    "        preds = model.predict_proba(x_vld)\n",
    "\n",
    "        log_scores = vld_scores.get('log loss', [])\n",
    "        log_scores.append(log_loss(y_vld, preds))\n",
    "        vld_scores['log loss'] = log_scores\n",
    "    return trn_scores, vld_scores\n",
    "\n",
    "def print_scores(trn_scores, vld_scores):\n",
    "    prefix = '        '\n",
    "    cols = ['log loss']\n",
    "    print('='*50)\n",
    "    print('TRAIN EVAL')\n",
    "    for col in cols:\n",
    "        print('-'*50)\n",
    "        print('# {}'.format(col))\n",
    "        print('# {} Mean : {}'.format(prefix, np.mean(trn_scores[col])))\n",
    "        print('# {} Raw  : {}'.format(prefix, trn_scores[col]))\n",
    "\n",
    "    print('='*50)\n",
    "    print('VALID EVAL')\n",
    "    for col in cols:\n",
    "        print('-'*50)\n",
    "        print('# {}'.format(col))\n",
    "        print('# {} Mean : {}'.format(prefix, np.mean(vld_scores[col])))\n",
    "        print('# {} Raw  : {}'.format(prefix, vld_scores[col]))\n",
    "\n",
    "def print_time(end, start):\n",
    "    print('='*50)\n",
    "    elapsed = end - start\n",
    "    print('{} secs'.format(round(elapsed)))\n",
    "    \n",
    "def fit_and_eval(trn, target, model):\n",
    "    trn_scores, vld_scores = evaluate(trn,target,model)\n",
    "    print_scores(trn_scores, vld_scores)\n",
    "    print_time(time.time(), st)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 피쳐 엔지니어링 (데이터 최적화) [+2]\n",
    "    - 직접 새로운 변수를 추가 혹은 기존 변수를 삭제하여서 최적의 변수세트 생성해보기\n",
    "    - 주의: 훈련 데이터에 수행한 변수 변환은 테스트 데이터에도 동일하게 수행해야함\n",
    "    - 힌트: 금융 상품에 대한 새로운 정보를 넣는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tiprel_1mes의 active, inactive 관계?\n",
    "\n",
    "age 의 첫번째 peak는 segmento의 college graduated 의 영향 -> college graduated & other model 분리 한다면?\n",
    "\n",
    "college graduated(segmento) 가입자들의 대부분은 가입채널 KHE(canal_entrada)을 통함\n",
    "\n",
    "소득에 따라 가입 채널이 차이가 있음 KAT(VIP) > KFC > KHE (college graduated) > other\n",
    "\n",
    "\n",
    "* 실험 특이사항\n",
    "\n",
    "fecha_alta, antiguedad(drop) extraTree-?\n",
    "\n",
    "cod_prov, nomprov(drop) extraTree+\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moonhwi\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "# 입력 : trn, target, tst\n",
    "# 출력 : new trn, new tst, same target\n",
    "\n",
    "## 중복되는 의미의 변수 제거\n",
    "trn = trn.drop(['fecha_alta'], axis = 1)\n",
    "tst = tst.drop(['fecha_alta'], axis = 1)\n",
    "trn = trn.drop(['nomprov'], axis = 1)\n",
    "tst = tst.drop(['nomprov'], axis = 1)\n",
    "\n",
    "## age renta log \n",
    "trn['age_log'] = np.log(trn['age']+1)\n",
    "tst['age_log'] = np.log(tst['age']+1)\n",
    "trn['renta_log'] = np.log(trn['renta']+1)\n",
    "tst['renta_log'] = np.log(tst['renta']+1)\n",
    "\n",
    "## age renta remove\n",
    "trn = trn.drop(['age'], axis = 1)\n",
    "tst = tst.drop(['age'], axis = 1)\n",
    "trn = trn.drop(['renta'], axis = 1)\n",
    "tst = tst.drop(['renta'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45595, 244) (929615, 244)\n",
      "(45595, 273) (929615, 273)\n"
     ]
    }
   ],
   "source": [
    "cols = ['ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'ind_cco_fin_ult1',\n",
    "        'ind_cder_fin_ult1', 'ind_cno_fin_ult1',  'ind_ctju_fin_ult1',\n",
    "        'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1',\n",
    "        'ind_deco_fin_ult1', 'ind_deme_fin_ult1', 'ind_dela_fin_ult1',\n",
    "        'ind_ecue_fin_ult1', 'ind_fond_fin_ult1', 'ind_hip_fin_ult1',\n",
    "        'ind_plan_fin_ult1', 'ind_pres_fin_ult1', 'ind_reca_fin_ult1',\n",
    "        'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1', 'ind_viv_fin_ult1',\n",
    "        'ind_nomina_ult1',   'ind_nom_pens_ult1', 'ind_recibo_ult1']\n",
    "\n",
    "print(trn.shape, tst.shape)\n",
    "\n",
    "# 타겟별 누적 합\n",
    "lags = ['_lag_one','_lag_two','_lag_thr','_lag_fou','_lag_fiv']\n",
    "for col in cols:\n",
    "    trn[col+'_sum'] = trn[[col+lag for lag in lags]].sum(axis=1)\n",
    "    tst[col+'_sum'] = tst[[col+lag for lag in lags]].sum(axis=1)\n",
    "    \n",
    "# 월별 누적 합\n",
    "for lag in lags:\n",
    "    trn['sum'+lag] = trn[[col+lag for col in cols]].sum(axis=1)\n",
    "    tst['sum'+lag] = tst[[col+lag for col in cols]].sum(axis=1)\n",
    "    \n",
    "print(trn.shape, tst.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antiguedad</th>\n",
       "      <th>canal_entrada</th>\n",
       "      <th>cod_prov</th>\n",
       "      <th>conyuemp</th>\n",
       "      <th>ind_actividad_cliente</th>\n",
       "      <th>ind_empleado</th>\n",
       "      <th>ind_nuevo</th>\n",
       "      <th>indext</th>\n",
       "      <th>indfall</th>\n",
       "      <th>indrel</th>\n",
       "      <th>...</th>\n",
       "      <th>ind_valo_fin_ult1_sum</th>\n",
       "      <th>ind_viv_fin_ult1_sum</th>\n",
       "      <th>ind_nomina_ult1_sum</th>\n",
       "      <th>ind_nom_pens_ult1_sum</th>\n",
       "      <th>ind_recibo_ult1_sum</th>\n",
       "      <th>sum_lag_one</th>\n",
       "      <th>sum_lag_two</th>\n",
       "      <th>sum_lag_thr</th>\n",
       "      <th>sum_lag_fou</th>\n",
       "      <th>sum_lag_fiv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>150</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>150</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>122</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>122</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>122</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 273 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   antiguedad  canal_entrada  cod_prov  conyuemp  ind_actividad_cliente  \\\n",
       "0          34            150        20         2                      1   \n",
       "1          34            150        20         2                      1   \n",
       "2          34            122        20         2                      1   \n",
       "3          34            122        20         2                      1   \n",
       "4          34            122        20         2                      1   \n",
       "\n",
       "   ind_empleado  ind_nuevo  indext  indfall  indrel     ...       \\\n",
       "0             3          0       0        0       0     ...        \n",
       "1             3          0       0        0       0     ...        \n",
       "2             3          0       0        0       0     ...        \n",
       "3             3          0       0        0       0     ...        \n",
       "4             3          0       0        0       0     ...        \n",
       "\n",
       "   ind_valo_fin_ult1_sum  ind_viv_fin_ult1_sum  ind_nomina_ult1_sum  \\\n",
       "0                    0.0                   0.0                  0.0   \n",
       "1                    0.0                   0.0                  0.0   \n",
       "2                    0.0                   0.0                  3.0   \n",
       "3                    0.0                   0.0                  3.0   \n",
       "4                    0.0                   0.0                  0.0   \n",
       "\n",
       "   ind_nom_pens_ult1_sum  ind_recibo_ult1_sum  sum_lag_one  sum_lag_two  \\\n",
       "0                    0.0                  0.0          0.0          0.0   \n",
       "1                    0.0                  0.0          0.0          0.0   \n",
       "2                    3.0                  5.0          3.0          5.0   \n",
       "3                    3.0                  5.0          3.0          5.0   \n",
       "4                    0.0                  5.0          2.0          2.0   \n",
       "\n",
       "   sum_lag_thr  sum_lag_fou  sum_lag_fiv  \n",
       "0          0.0          0.0          0.0  \n",
       "1          0.0          0.0          0.0  \n",
       "2          5.0          3.0          5.0  \n",
       "3          5.0          3.0          5.0  \n",
       "4          2.0          2.0          2.0  \n",
       "\n",
       "[5 rows x 273 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습 및 평가\n",
    "    - 모델 종류\n",
    "        - Decision Tree : 트리 기반 모델\n",
    "        - Logistic Regression : 선형 모델\n",
    "        - RandomForest, ExtraTrees : 트리 기반 앙상블 모델\n",
    "        - BaggingClassifier : 앙상블 모델\n",
    "        - (XGBoost) : 트리 기반 앙상블 모델\n",
    "        \n",
    "    - 훈련/검증 데이터 기반 평가 척도\n",
    "        - Log Loss\n",
    "        \n",
    "    - 검증 데이터 Log Loss 목표 수치 = 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3회차 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-1496bebe949a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrf_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m180\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m777\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfit_and_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrf_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[1;31m# 5 sec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-212eab0c9973>\u001b[0m in \u001b[0;36mfit_and_eval\u001b[0;34m(trn, target, model)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfit_and_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mtrn_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvld_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mprint_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrn_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvld_scores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mprint_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-212eab0c9973>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(x, y, model)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[1;31m# fit model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_trn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_trn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[1;31m# eval _ trn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\moonhwi\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \"\"\"\n\u001b[1;32m    246\u001b[0m         \u001b[1;31m# Validate or convert input data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\moonhwi\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    406\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\moonhwi\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 58\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=180, max_depth=13, n_jobs=-1, random_state=777)\n",
    "fit_and_eval(trn, target, rf_model)\n",
    "# 5 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-5a96ad7b9201>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0met_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExtraTreesClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m777\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfit_and_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0met_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[1;31m# 6 sec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-212eab0c9973>\u001b[0m in \u001b[0;36mfit_and_eval\u001b[0;34m(trn, target, model)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfit_and_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mtrn_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvld_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mprint_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrn_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvld_scores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mprint_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-212eab0c9973>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(x, y, model)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[1;31m# fit model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_trn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_trn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[1;31m# eval _ trn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\moonhwi\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \"\"\"\n\u001b[1;32m    246\u001b[0m         \u001b[1;31m# Validate or convert input data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\moonhwi\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    406\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\moonhwi\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 58\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "et_model = ExtraTreesClassifier(n_estimators=50, max_depth=13, n_jobs=-1, random_state=777)\n",
    "fit_and_eval(trn, target, et_model)\n",
    "# 6 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 매개변수 및 주요 변수 시각화 (1)\n",
    "    - Decision Tree, RandomForest, ExtraTrees 전용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility\n",
    "\n",
    "def observe_model_tree(trn, model):\n",
    "    print('='*50)\n",
    "    print(model)\n",
    "    \n",
    "    print('='*50)\n",
    "    print('# Feature Importance')\n",
    "    print(model.feature_importances_)\n",
    "    \n",
    "    print('-'*50)\n",
    "    print('# Mapped to Column Name')\n",
    "    prefix = '    '\n",
    "    feature_importance = dict()\n",
    "    for i, f_imp in enumerate(model.feature_importances_):\n",
    "        print('{} {} \\t {}'.format(prefix, round(f_imp,5), trn.columns[i]))\n",
    "        feature_importance[trn.columns[i]] = f_imp\n",
    "\n",
    "    print('-'*50)\n",
    "    print('# Sorted Feature Importance')\n",
    "    feature_importance_sorted = sorted(feature_importance.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    for item in feature_importance_sorted:\n",
    "        print('{} {} \\t {}'.format(prefix, round(item[1],5), item[0]))\n",
    "    \n",
    "    return feature_importance_sorted\n",
    "\n",
    "def plot_fimp(fimp):\n",
    "    x = []; y = []\n",
    "    for item in fimp:\n",
    "        x.append(item[0])\n",
    "        y.append(item[1])\n",
    "\n",
    "    f, ax = plt.subplots(figsize=(20, 15))\n",
    "    sns.barplot(x,y,alpha=0.5)\n",
    "    ax.set_title('Feature Importance for Model : Decision Tree')\n",
    "    ax.set(xlabel='Column Name', ylabel='Feature Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 모델 상세 보기\n",
    "rf_fimp = observe_model_tree(trn, rf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 주요 변수 시각화\n",
    "plot_fimp(rf_fimp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 모델 상세 보기\n",
    "et_fimp = observe_model_tree(trn, et_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 주요 변수 시각화\n",
    "plot_fimp(et_fimp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 캐글에 직접 결과물 제출하기\n",
    "    - MAP@7 평가척도를 기반 (https://www.kaggle.com/c/santander-product-recommendation/details/evaluation)\n",
    "    - 유저당 상위 7개의 제품을 추천해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 최종 모델 정의하기\n",
    "model = RandomForestClassifier(n_estimators=180, max_depth=13, n_jobs=-1, random_state=777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "print('='*50)\n",
    "print('# Test shape : {}'.format(tst.shape))\n",
    "\n",
    "model.fit(trn,target)\n",
    "\n",
    "preds = model.predict_proba(tst)\n",
    "preds = np.fliplr(np.argsort(preds, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'ind_cco_fin_ult1',\n",
    "        'ind_cder_fin_ult1', 'ind_cno_fin_ult1',  'ind_ctju_fin_ult1',\n",
    "        'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1',\n",
    "        'ind_deco_fin_ult1', 'ind_deme_fin_ult1', 'ind_dela_fin_ult1',\n",
    "        'ind_ecue_fin_ult1', 'ind_fond_fin_ult1', 'ind_hip_fin_ult1',\n",
    "        'ind_plan_fin_ult1', 'ind_pres_fin_ult1', 'ind_reca_fin_ult1',\n",
    "        'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1', 'ind_viv_fin_ult1',\n",
    "        'ind_nomina_ult1',   'ind_nom_pens_ult1', 'ind_recibo_ult1']\n",
    "target_cols = [cols[i] for i, col in enumerate(cols) if i in rem_targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_preds = []\n",
    "for pred in preds:\n",
    "    top_products = []\n",
    "    for i, product in enumerate(pred):\n",
    "        top_products.append(target_cols[product])\n",
    "        if i == 6:\n",
    "            break\n",
    "    final_preds.append(' '.join(top_products))\n",
    "\n",
    "temp = pd.read_csv('../input/test_clean.csv')\n",
    "test_id = temp['ncodpers']\n",
    "out_df = pd.DataFrame({'ncodpers':test_id, 'added_products':final_preds})\n",
    "file_name = datetime.now().strftime(\"result_%Y%m%d%H%M%S\") + '.csv'\n",
    "out_df.to_csv(os.path.join('../output',file_name), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과물 출력은 https://www.kaggle.com/c/santander-product-recommendation/submissions/attach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 나만의 머신러닝 파이프라인 흐름도(Flow Chart) 기록하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 원천 데이터\n",
    "    - .\n",
    "\n",
    "- 전처리\n",
    "    - .\n",
    "\n",
    "- 피쳐 엔지니어링 이전 데이터 dimension\n",
    "    - .\n",
    "\n",
    "- 피쳐 엔지니어링 \n",
    "    - .\n",
    "\n",
    "- 피쳐 엔지니어링 이후 데이터 dimension\n",
    "    - .\n",
    "\n",
    "- 모델 튜닝 \n",
    "    - .\n",
    "\n",
    "- 검증 결과 \n",
    "    - .\n",
    "\n",
    "- 실제 결과 \n",
    "    - ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 예시\n",
    "\n",
    "- 원천 데이터 \n",
    "    - Kaggle 경진대회 데이터 train_ver2.csv, test_ver2.csv (Link: https://www.kaggle.com/c/santander-product-recommendation/data)\n",
    "\n",
    "\n",
    "- 전처리 \n",
    "    - 결측값을 .fillna 함수를 통해 0으로 대체. (기존 데이터에 0이 존재할 경우 -1로 대체)\n",
    "\n",
    "\n",
    "- 피쳐 엔지니어링 이전 데이터 dimension:\n",
    "    - trn : (45619, 246)\n",
    "    - target : (45619, 1) [18 classes]\n",
    "    - tst : (929615, 246)\n",
    "\n",
    "\n",
    "- 피쳐 엔지니어링\n",
    "    - age_log : log(age + 1)\n",
    "    - ind..._lag_one : 5월 사용자별 금융상품 보유현황\n",
    "    - ind..._lag_two : 4월 사용자별 금융상품 보유현황\n",
    "    - ind..._lag_thr : 3월 사용자별 금융상품 보유현황\n",
    "\n",
    "\n",
    "- 피쳐 엔지니어링 이후 데이터 dimension:\n",
    "    - trn : (45619, 250)\n",
    "    - target : (45619, 1) [18 classes]\n",
    "    - tst : (929615, 250)\n",
    "\n",
    "\n",
    "- 모델 튜닝 \n",
    "    - RandomForest : max_depth = 20 로 복잡도 조정\n",
    "\n",
    "\n",
    "- 검증 결과 \n",
    "    - trn logloss : 1.18\n",
    "    - vld logloss : 1.28\n",
    "\n",
    "\n",
    "- 실제 결과 \n",
    "    - Public Leaderboard : 0.025984\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "    - RandomForest vs ExtraTrees 의 차이란?\n",
    "        - P. Geurts, D. Ernst., and L. Wehenkel, “Extremely randomized trees”, Machine Learning, 63(1), 3-42, 2006\n",
    "        - 1) ET의 경우, 변수 샘플링을 boostrap 샘플이 아닌 전체 데이터에서 취한다.\n",
    "        - 2) ET의 경우, 샘플내 분포에 상관없이 완전한 임의 샘플링으로 데이터 샘플을 취한다."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
